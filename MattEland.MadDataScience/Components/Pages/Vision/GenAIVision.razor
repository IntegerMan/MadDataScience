@page "/Vision/GenAIVision"
@inject ILogger<GenAIVision> Logger
@inject AzureOpenAiChatService ChatService
@inject SpeechService SpeechService

<MudContainer MaxWidth="MaxWidth.Medium" Class="mx-auto my-8">
<MudText Typo="Typo.h4">Chatting with Images</MudText>
<MudText Typo="Typo.subtitle1" Class="mb-8">
    Some LLMs can also interpret images and generate images of their own.
</MudText>

<img src="@ImageSource" alt="Sample Image" class="img-fluid"/>
<br/>

@if (Description is not null)
{
    <MudText Typo="Typo.h6" Class="mt-4">Image Description</MudText>
    <MudText Typo="Typo.caption">@Description</MudText>
}
<br/>

@if (IsBusy)
{
    <MudProgressLinear Indeterminate="true" Color="Color.Primary"/>
}

<MudButton Class="mt-4" Disabled="IsBusy" @onclick="HandleDescribeClick" Variant="Variant.Filled" Color="Color.Primary">
    Describe This
</MudButton>
</MudContainer>

@code {
    public Uri ImageSource { get; set; } = new Uri("https://www.danylkoweb.com/content/images/collection-codemash.jpg");
    public string? Description { get; set; }
    public bool IsBusy { get; set; }
    public string VoiceName { get; set; } = "en-US-GuyNeural";
    
    private async Task HandleDescribeClick()
    {
        IsBusy = true;
        StateHasChanged();

        string prompt = "You are DogOS, a cute and playful AI assistant at KidzMash conference at CodeMash. The user has given you an image to look at. Talk about what you see, from the perspective of a dog. Being silly is fine, but keep it to a few sentences. Please avoid emojis.";
        string description = await ChatService.DescribeImageAsync(prompt, ImageSource);
        
        Logger.LogInformation("Described Image {ImageSource} as {Description}", ImageSource, description);
        Description = description;
        IsBusy = false;
        
        // Do not wait for voice
        _ = SpeechService.SpeakAsync(description, VoiceName);
    }

}